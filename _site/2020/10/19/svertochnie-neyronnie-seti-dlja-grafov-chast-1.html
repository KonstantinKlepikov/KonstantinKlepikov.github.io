<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Сверточные нейронные сети для графов. Часть 1 | My deep learning</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="Сверточные нейронные сети для графов. Часть 1" />
<meta name="author" content="Klepikov Konstantin" />
<meta property="og:locale" content="ru_RU" />
<meta name="description" content="Блог про нейронные сети и машинное обучение" />
<meta property="og:description" content="Блог про нейронные сети и машинное обучение" />
<link rel="canonical" href="https://konstantinklepikov.github.io/2020/10/19/svertochnie-neyronnie-seti-dlja-grafov-chast-1.html" />
<meta property="og:url" content="https://konstantinklepikov.github.io/2020/10/19/svertochnie-neyronnie-seti-dlja-grafov-chast-1.html" />
<meta property="og:site_name" content="My deep learning" />
<meta property="og:image" content="https://konstantinklepikov.github.io/assets/img/191020banner.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-19T00:00:00+02:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","description":"Блог про нейронные сети и машинное обучение","headline":"Сверточные нейронные сети для графов. Часть 1","dateModified":"2020-10-19T00:00:00+02:00","datePublished":"2020-10-19T00:00:00+02:00","image":"https://konstantinklepikov.github.io/assets/img/191020banner.png","author":{"@type":"Person","name":"Klepikov Konstantin"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://konstantinklepikov.github.io/2020/10/19/svertochnie-neyronnie-seti-dlja-grafov-chast-1.html"},"url":"https://konstantinklepikov.github.io/2020/10/19/svertochnie-neyronnie-seti-dlja-grafov-chast-1.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <meta name="keywords" content="Сверточная нейронная сеть граф graph convolutional neural network GCN эмбеддинги embedding">

  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link rel="icon" href="/assets/img/favicon.ico" type="image/x-icon">
  <link rel="shortcut icon" href="/assets/img/favicon.ico" type="image/x-icon">

  
  
  <link rel="stylesheet" href="https://konstantinklepikov.github.io/assets/style.css">

  
      <!-- Yandex.Metrika counter -->
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(53548570, "init", {
        clickmap:true,
        trackLinks:true,
        accurateTrackBounce:true
    });
  </script>
  <noscript><div><img src="https://mc.yandex.ru/watch/53548570" style="position:absolute; left:-9999px;" alt="" /></div></noscript>
    <!-- /Yandex.Metrika counter -->
      <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-139620627-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-139620627-1');
  </script>
  

  <link rel="canonical" href="https://konstantinklepikov.github.io/2020/10/19/svertochnie-neyronnie-seti-dlja-grafov-chast-1.html">
  <link rel="alternate" type="application/rss+xml" title="My deep learning" href="https://konstantinklepikov.github.io/feed.xml">

  <script async defer src="https://buttons.github.io/buttons.js"></script>

  <!-- Mathjax Support -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
  
  
    





  
</head>


  <body>

    <header class="border-bottom-thick px-2 clearfix">
  <div class="left sm-width-full py-1 mt-1 mt-lg-0">
    <a class="align-middle link-primary" href="/">
      My deep learning
    </a>
  </div>
  <div class="right sm-width-full">
    <ul class="list-reset mt-lg-1 mb-2 mb-lg-1">
      
        
      
        
        <li class="inline-block">
          <a class="align-middle link-primary mr-2 mr-lg-0 ml-lg-2" href="/about/">
            Об авторе
          </a>
        </li>
        
      
        
      
        
        <li class="inline-block">
          <a class="align-middle link-primary mr-2 mr-lg-0 ml-lg-2" href="/allposts/">
            Все посты
          </a>
        </li>
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
        <li class="inline-block">
          <a class="align-middle link-primary mr-2 mr-lg-0 ml-lg-2" href="/links/">
            Ссылки
          </a>
        </li>
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
      <li class="inline-block">
    <a class="align-middle link-primary mr-2 mr-lg-0 ml-lg-2" href="https://konstantinklepikov.github.io/myknowlegebase/">
        My knowlege base
    </a>
</li>
    </ul>
  </div>
</header>


    <div>
      <article class="container px-2 mx-auto mb4" itemscope itemtype="http://schema.org/BlogPosting">
  <h1 class="h1 col-9 sm-width-full py-4 mt-3 inline-block" itemprop="name headline">Сверточные нейронные сети для графов. Часть 1</h1>
  <div class="col-4 sm-width-full mt-1 border-top-thin">
    <p class="py-2 bold h4"><time datetime="2020-10-19T00:00:00+02:00" itemprop="datePublished">Oct 19, 2020</time></p>
    <p class="mb-3 h5">Теги:
    
      
      <a href="/tag/neural-network" title="neural-network" class="link-tags">neural-network&nbsp;</a>
    
      
      <a href="/tag/graphs" title="graphs" class="link-tags">graphs&nbsp;</a>
    
      
      <a href="/tag/convolutional" title="convolutional" class="link-tags">convolutional&nbsp;</a>
    
      
      <a href="/tag/cs224w" title="cs224w" class="link-tags">cs224w&nbsp;</a>
    
      
      <a href="/tag/gcn" title="gcn" class="link-tags">gcn&nbsp;</a>
    
      
      <a href="/tag/embedding" title="embedding" class="link-tags">embedding&nbsp;</a>
    
    </p>
  </div>

  <div class="prose" itemprop="articleBody">
      <p><img src="../../../assets/img/191020banner.png" alt="Сверточные нейронные сети для графов. Часть 1" /></p>

<p>Графовые нейронные сети — молодое и перспективное направление развития нейронных сетей, нашедшее применение в анализе различных структур данных, например, социальных профилей, групп документов, в молекулярной биологии, трехмерных изображений и т.д. и т.п. В данной статье разбираются подходы к решению проблемы работы с графовыми данными.</p>

<p>Главная сложность — разыскать такое представление графа, которое отобразит графовую структуру в модель машинного обучения. Решается это такими методами:</p>

<ul>
  <li>графовые статистики</li>
  <li>ядерные методы</li>
  <li>манипуляции с признаками для оценки локальной близости</li>
  <li>обучение представлению графа</li>
</ul>

<p>Представление информации в нодах или субграфах в виде векторов — проблема. Оказывается, как правило, данные содержатся в многомерном неевклидовом пространстве. Соответственно <strong>задача — перегнать многомерный вектор признаков в низкоразмерный, размерностью <script type="math/tex">d</script>, желательно из <script type="math/tex">\mathbb{R}</script></strong>.</p>

<p>Одним из основных подходов в решении данной задачи является representation learning. Подход сводится к созданию эмбеддингов для нод или субграфов в графе, что позволяет перевести данные в область с низкой размерностью. Такие эмбеддинги уже можно использовать в различных моделей ML.</p>

<p>Если мы имеем граф <script type="math/tex">G = (V, E)</script> и ассоциированные с ним матрицу смежности <script type="math/tex">A</script> и матрицу <script type="math/tex">X</script>, содержащую атрибуты нод, так что <script type="math/tex">X \in \mathbb{R}^{m \times \vert V \vert}</script>, то задачей является получение векторов <script type="math/tex">z \in \mathbb{R}^d</script> для каждой ноды, таких, что <script type="math/tex">d \ll \vert V \vert</script>. (Данный подход справедлив и для ребер).</p>

<p>Эту задачу решает такая модель:</p>

<ul>
  <li>функция попарной похожести (pairwise similarity function) <script type="math/tex">S_g : V \times V \rightarrow \mathbb{R}^+</script>, определенная над графом <script type="math/tex">G</script>. Функция измеряет схожесть между нодами.</li>
  <li>энкодер, генерирующий эмбеддинги <script type="math/tex">ENC: V \rightarrow  \mathbb{R}^d</script></li>
  <li>декодер, реконструирующий статистики графа из эмбеддингов <script type="math/tex">DEC : \mathbb{R}^d \times \mathbb{R}^d \rightarrow \mathbb{R}^+</script> *</li>
  <li>функция потерь (специфична для каждой задачи) - оценивает несоответствие между декодированным (оцененным) значением близости <script type="math/tex">DEC(\mathbf{z}_i, \mathbf{z}_j)</script> и истинным <script type="math/tex">S_g(v_i, v_j)</script></li>
</ul>

<p>* для двух нод в графе <script type="math/tex">DEC(ENC(v_i), ENC(v_j)) = DEC(\mathbf{z}_i, \mathbf{z}_j) \approx S_g(v_i, v_j)</script> декодер восстанавливает «попарную близость» нод в графе из эмбеддингов</p>

<p>Самый простой метод — <strong>shallow encoding</strong>, для которого мы можем определить энкодер как функцию: <script type="math/tex">ENC(v_i) = Z v_i</script>, где <script type="math/tex">Z \in \mathbb{R}^{m \times \vert V \vert}</script>.</p>

<p><img src="../../../assets/img/191020-03.png" alt="shallow" /></p>

<p>К подобным способам создания эмбеддингов относятся различные матричные факторизации (graph factorisation, GraRep, HOPE и т.д.) и RandomWalk модели (DeepWalk, node2wec).</p>

<p>Проблемой shallow encoding является то, что в этом методе параметры нод не распространяются и не используются совместно в энкодере. Каждый вектор обучается отдельно от других. Число параметров растет как функция от количества нод <script type="math/tex">O(V)</script>. Кроме того, подход не учитывает атрибуты нод, которые в большинстве случаев содержат важную информацию о графе. К тому же подход генерирует эмбеддинги только для данных, которые есть среди обучаемых. Модель проблематично обобщить на данные, которые модель никогда не видела.</p>

<p>Чтобы справиться с недостатками shallow encoding, были изобретены генерализованные энкодер-декодер структуры: DNGR (deep neural graph representation) и SDNE (structural deep network embeddings), относящихся к автоэнкодерам, основанных на исследовании соседних нод в графе.</p>

<p>Прямым решением для таких моделей является то, что каждая нода <script type="math/tex">v_i</script> ассоциируется с высокаразмерным «вектором близости» <script type="math/tex">S_i \in \mathbb{R}^{\vert V \vert}</script>, содержащем информацию о близости ноды ко всем другим нодам в графе. Затем данный вектор сжимается до нужной размерности. Проблема такого подхода в том, что он невероятно дорогой. К тому же метод статичный и плохо работает с изменяющимися графами.</p>

<p>Другой подход — <strong>neighbourhood agregation</strong> атрибутов нод для генерации эмбеддингов. Этот метод позволяет агрегировать «месседжи» от соседей ноды, которые, в свою очередь, базируются на «месседжах», агрегированных по соседям соседей и т.д. Иногда такие модели называют сверточными энкодерами из-за схожести их архитектуры со свертками.</p>

<p><img src="../../../assets/img/191020-01.png" alt="neighbourhood agregation" /></p>

<p>Алгоритм такой сети выглядит так (взято из статьи Representation Learning on Graphs: Methods and Applicationsб Hamilton, William L.; Ying, Rex; Leskovec, Jure);</p>

<p><img src="../../../assets/img/191020-02.png" alt="neighbourhood agregation algorythm" /></p>

<ul>
  <li>Алгоритм строит эмбеддинги для нод рекурсивно</li>
  <li>Вначале энкодер инициализируется атрибутами нод</li>
  <li>Затем на каждой итерации агрегируются эмбеддинги соседей</li>
  <li>Далее каждая нода получает новый эмбеддинг, скомбинированный из ее собственного эмбеддинга и агрегированного вектора.</li>
  <li>Затем все это отправляется в полносвязный слой и процесс повторяется K раз.</li>
</ul>

<p>Эмбеддинг каждой ноды обогащается данными своих соседей, при этом размерность векторов остается постоянной во время всей процедуры. В результате мы получаем векторное представление графа.</p>

<p>Этот подход эксплуатируют:</p>

<ul>
  <li>GNN (graph neural network)</li>
  <li>GCN (graph convolutional networks)</li>
  <li>column networks</li>
  <li>GraphSAGE</li>
</ul>

<p>Разные подтипы модели определяются разными агрегирующей функцией и комбинирующей вектора функцией.</p>

<h4 id="gcn">GCN</h4>

<ul>
  <li>агрегирующая функция - поэлементное среднее</li>
  <li>комбинируем взвешенной суммой</li>
</ul>

<h4 id="column-network">column network</h4>

<ul>
  <li>то же самое, что и в GCN, только на выходе цикла стоит функция интерполяции, позволяющая сохранять локальную информацию в процессе итерации)</li>
</ul>

<h4 id="graphsage">GraphSAGE</h4>

<ul>
  <li>агрегирует среднее, макспуллинг или LSTM</li>
  <li>комбинируем конкатенацией</li>
</ul>

<h4 id="gnn">GNN</h4>

<p>GNN — обобщающая вышеизложенные принципы модель. По сути, GNN описывает множество возможных реализаций, одна из которых — GCN, где в качестве основного механизма используется свертка.</p>

<p>В базовой реализации, алгоритм инициализируется случайным эмбеддингом для каждой ноды и на каждой итерации эмбеддинги накапливают информацию о своих соседях вот таким образом:</p>

<p><img src="../../../assets/img/191020-04.png" alt="GNN embeddings" /></p>

<p>где <script type="math/tex">h</script> — это произвольная дифференцируемая функция вида <script type="math/tex">р: \mathbb{R}^d \times \mathbb{R}^m \times \mathbb{R}^m \rightarrow \mathbb{R}^d</script>. На выходе после <script type="math/tex">K</script> итераций мы должны получить вектор вида <script type="math/tex">\mathbf{z}_{v_i} = g({\mathbf{h}_i}^K)</script>, где <script type="math/tex">g</script> - произвольная дифференцируемая функция вида <script type="math/tex">g: \mathbb{R}^d \rightarrow \mathbb{R}^d</script>, иными словами, это некая нейросеть, возможно MLP.</p>

<p>Практическую часть к данной статье смотрите <a href="/2020/11/05/svertochnie-neyronnie-seti-dlja-grafov-chast-2-practica.html">тут</a>.</p>

  </div>
    <script src="https://utteranc.es/client.js"
        repo="KonstantinKlepikov/KonstantinKlepikov.github.io"
        issue-term="url"
        label="blog-comments"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
    <div class="pay">
    <iframe src="https://yoomoney.ru/quickpay/shop-widget?writer=seller&targets=%D0%9F%D0%BE%D0%B4%D0%B4%D0%B5%D1%80%D0%B6%D0%B0%D1%82%D1%8C%20%D1%81%D0%B0%D0%B9%D1%82%20konstantinklepikov.github.io&targets-hint=%D0%9D%D0%B0%20%D0%BF%D0%BE%D0%B4%D0%B4%D0%B5%D1%80%D0%B6%D0%BA%D1%83%20%D1%81%D0%B0%D0%B9%D1%82%D0%B0&default-sum=100&button-text=12&payment-type-choice=on&mobile-payment-type-choice=on&hint=&successURL=https%3A%2F%2Fkonstantinklepikov.github.io%2F&quickpay=shop&account=410013688263668&" width="100%" height="250" frameborder="0" allowtransparency="true" scrolling="no"></iframe>
</div>


  <p class="h4 mt-2">Все статьи с тегом <a href="/tag/gcn" class="link-tags">gcn</a></p>
  <div class="prose mb-2">
    <ul>
        
        <li><a href="/2020/11/05/svertochnie-neyronnie-seti-dlja-grafov-chast-2-practica.html" title="Сверточные нейронные сети для графов. Часть 2 (практика)">Сверточные нейронные сети для графов. Часть 2 (практика)</a> (05 Nov 2020)<br>
            
        </li>
        
        <li><a href="/2020/10/19/svertochnie-neyronnie-seti-dlja-grafov-chast-1.html" title="Сверточные нейронные сети для графов. Часть 1">Сверточные нейронные сети для графов. Часть 1</a> (19 Oct 2020)<br>
            
        </li>
        
    </ul>
  </div>

</article>

<div class="container mx-auto px-2 py-2 clearfix">
  <!-- Use if you want to show previous and next for all posts. -->



  <div class="col-4 sm-width-full left mr-lg-4 mt-3">
    <a class="no-underline border-top-thin py-1 block" href="https://konstantinklepikov.github.io/2020/10/09/breadth-first-and-depth-first-search-algorithms.html" title="Алгоритмы поиска в ширину и в глубину">
      <span class="h5 link-secondary text-accent">Предыдущая запись</span>
      <p class="bold h3 link-primary mb-1">Алгоритмы поиска в ширину и в глубину</p>
      <p>Поиск в ширину и поиск в глубину представляют две основных парадигмы обхода графов. Поиск в ширину (breadth-first search, BFS) Алгоритм...</p>
    </a>
  </div>



  <div class="col-4 sm-width-full left mt-3">
    <a class="no-underline border-top-thin py-1 block" href="https://konstantinklepikov.github.io/2020/11/05/svertochnie-neyronnie-seti-dlja-grafov-chast-2-practica.html" title="Сверточные нейронные сети для графов. Часть 2 (практика)">
      <span class="h5 link-secondary text-accent">Следующая запись</span>
      <p class="bold h3 link-primary mb-1">Сверточные нейронные сети для графов. Часть 2 (практика)</p>
      <p>Семинар, посвященный практике по графовым нейронным сетям, можно посмотреть на youtube: Вначале еще раз разбираем [теоретическую часть вопроса]({{site.baseurl}}{% link _posts/2020-10-19-svertochnie-neyronnie-seti-dlja-grafov-chast-1.md...</p>
    </a>
  </div>


</div>

    </div>

    <div class="border-top-thin clearfix mt-2 mt-lg-4">
  <div class="container mx-auto px-2">
    <p class="col-8 sm-width-full left py-2 mb-0">Этот проект поддерживается <a class="text-accent" href="https://github.com/KonstantinKlepikov">KonstantinKlepikov</a></p>
    <ul class="list-reset right clearfix sm-width-full py-2 mb-2 mb-lg-0">
      <li class="inline-block mr-1">
        <a href="https://twitter.com/share" class="twitter-share-button" data-hashtags="My deep learning">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
      </li>
      <li class="inline-block">
        <a class="github-button" href="https://github.com/KonstantinKlepikov/" data-icon="octicon-star" data-count-href="KonstantinKlepikov//stargazers" data-count-api="/repos/KonstantinKlepikov/#stargazers_count" data-count-aria-label="# stargazers on GitHub" aria-label="Star KonstantinKlepikov/ on GitHub">Star</a>
      </li>
    </ul>
  </div>
</div>


  </body>

</html>
