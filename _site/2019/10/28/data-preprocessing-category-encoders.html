<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Подготовка данных: кодирование категориальных признаков | My deep learning</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="Подготовка данных: кодирование категориальных признаков" />
<meta name="author" content="Klepikov Konstantin" />
<meta property="og:locale" content="ru_RU" />
<meta name="description" content="В статье «особенности препроцессинга данных в scikit-learn» разбирались особенности кодирования признаков с помощью библиотеки scikit-learn. К сожалению, набор инструментов scikit-learn довольно скромный." />
<meta property="og:description" content="В статье «особенности препроцессинга данных в scikit-learn» разбирались особенности кодирования признаков с помощью библиотеки scikit-learn. К сожалению, набор инструментов scikit-learn довольно скромный." />
<link rel="canonical" href="https://konstantinklepikov.github.io/2019/10/28/data-preprocessing-category-encoders.html" />
<meta property="og:url" content="https://konstantinklepikov.github.io/2019/10/28/data-preprocessing-category-encoders.html" />
<meta property="og:site_name" content="My deep learning" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-10-28T00:00:00+02:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","description":"В статье «особенности препроцессинга данных в scikit-learn» разбирались особенности кодирования признаков с помощью библиотеки scikit-learn. К сожалению, набор инструментов scikit-learn довольно скромный.","headline":"Подготовка данных: кодирование категориальных признаков","dateModified":"2019-10-28T00:00:00+02:00","datePublished":"2019-10-28T00:00:00+02:00","author":{"@type":"Person","name":"Klepikov Konstantin"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://konstantinklepikov.github.io/2019/10/28/data-preprocessing-category-encoders.html"},"url":"https://konstantinklepikov.github.io/2019/10/28/data-preprocessing-category-encoders.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <meta name="keywords" content="подготовка данных машинное обучение препроцессинг катигориальные признаки machine learning category encoders">

  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link rel="icon" href="/assets/img/favicon.ico" type="image/x-icon">
  <link rel="shortcut icon" href="/assets/img/favicon.ico" type="image/x-icon">

  
  
  <link rel="stylesheet" href="https://konstantinklepikov.github.io/assets/style.css">

  
      <!-- Yandex.Metrika counter -->
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(53548570, "init", {
        clickmap:true,
        trackLinks:true,
        accurateTrackBounce:true
    });
  </script>
  <noscript><div><img src="https://mc.yandex.ru/watch/53548570" style="position:absolute; left:-9999px;" alt="" /></div></noscript>
    <!-- /Yandex.Metrika counter -->
      <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-139620627-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-139620627-1');
  </script>
  

  <link rel="canonical" href="https://konstantinklepikov.github.io/2019/10/28/data-preprocessing-category-encoders.html">
  <link rel="alternate" type="application/rss+xml" title="My deep learning" href="https://konstantinklepikov.github.io/feed.xml">

  <script async defer src="https://buttons.github.io/buttons.js"></script>

  <!-- Mathjax Support -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
  
  
    





  
</head>


  <body>

    <header class="border-bottom-thick px-2 clearfix">
  <div class="left sm-width-full py-1 mt-1 mt-lg-0">
    <a class="align-middle link-primary text-accent" href="/">
      My deep learning
    </a>
  </div>
  <div class="right sm-width-full">
    <ul class="list-reset mt-lg-1 mb-2 mb-lg-1">
      
        
      
        
      
        
      
        
      
        
        <li class="inline-block">
          <a class="align-middle link-primary mr-2 mr-lg-0 ml-lg-2" href="/about/">
            Об авторе
          </a>
        </li>
        
      
        
      
        
        <li class="inline-block">
          <a class="align-middle link-primary mr-2 mr-lg-0 ml-lg-2" href="/allposts/">
            Все посты
          </a>
        </li>
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
        <li class="inline-block">
          <a class="align-middle link-primary mr-2 mr-lg-0 ml-lg-2" href="/links/">
            Ссылки
          </a>
        </li>
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
      <li class="inline-block">
    <a class="align-middle link-primary mr-2 mr-lg-0 ml-lg-2" href="https://konstantinklepikov.github.io/myknowlegebase/">
        My knowlege base
    </a>
</li>
    </ul>
  </div>
</header>


    <div>
      <article class="container px-2 mx-auto mb4" itemscope itemtype="http://schema.org/BlogPosting">
  <h1 class="h1 col-9 sm-width-full py-4 mt-3 inline-block" itemprop="name headline">Подготовка данных: кодирование категориальных признаков</h1>
  <div class="col-4 sm-width-full mt-1 border-top-thin">
    <p class="py-2 bold h4"><time datetime="2019-10-28T00:00:00+02:00" itemprop="datePublished">Oct 28, 2019</time></p>
    <p class="mb-3 h5">Теги: 
    
      
      <a href="/tag/preprocessing" title="preprocessing" class="link-tags">preprocessing&nbsp;</a>
    
      
      <a href="/tag/category-encoders" title="category-encoders" class="link-tags">category-encoders&nbsp;</a>
    
      
      <a href="/tag/sklearn" title="sklearn" class="link-tags">sklearn&nbsp;</a>
    
      
      <a href="/tag/scikit-learn" title="scikit-learn" class="link-tags">scikit-learn&nbsp;</a>
    
      
      <a href="/tag/ml-data" title="ml-data" class="link-tags">ml-data&nbsp;</a>
    
    </p>
  </div>

  <div class="prose" itemprop="articleBody">
      <p>В статье «<a href="/2019/10/08/scikit-learn-preprocessing.html">особенности препроцессинга данных в scikit-learn</a>» разбирались особенности кодирования признаков с помощью библиотеки scikit-learn. К сожалению, набор инструментов scikit-learn довольно скромный.</p>

<p>Часто данные содержат множественные категориальные признаки с разными представлениями категорий. В некоторых случаях категорий оказывается сравнительно много, по отношению к общему объему данных. Иногда значения в категориальных признаках имеют различные распределения, могут иметь как явный, так и неочевидный порядок. Все это не добавляет энтузиазма во время предварительной обработки.</p>

<p>К счастью, есть готовые решения, например библиотека <strong><a href="https://contrib.scikit-learn.org/categorical-encoding/">Category Encoders</a> (CE)</strong>, предоставляющая широкий набор кодировщиков категориальных признаков.</p>

<h2 id="какие-преимущества-у-ce">Какие преимущества у CE</h2>

<ol>
  <li>
    <p>Наверное, самое основное — это полная совместимость с scikit-learn. Доступны методы fit, fit_transform, get_params, set_params и transform. На основе CE можно строить пайплайны в scikit-learn.</p>
  </li>
  <li>
    <p>Поддержка numpy и pandas. Что важно — pandas dataframe можно получить и на выходе кодировщика. Иногда это весьма полезно, особенно когда нужно выполнить выборочное кодирование. Это позволяет не городить самодельный забор из кодировщиков, а использовать CE непосредственно в последовательном пайплайне scikit-learn.</p>
  </li>
  <li>
    <p>Есть возможность задать маску для кодирования, т.е. сделать выборочное кодирование</p>
  </li>
  <li>
    <p>Можно отбросить часть данных</p>
  </li>
  <li>
    <p>Спроектированный кодировщик отлично портируется на рабочие данные.</p>
  </li>
</ol>

<h2 id="какие-задачи-можно-решать-с-помощью-ce">Какие задачи можно решать с помощью CE</h2>

<ul>
  <li>
    <p>кодирование номинальных признаков (nominal) — признаки, порядок которых не определен (часто в табличных данных к таким признакам относятся распределения по цветам или по городам)</p>
  </li>
  <li>
    <p>кодирование упорядоченных признаков (ordinal) — признаки, порядок которых можно считать определенным (например, распределение по яркости)</p>
  </li>
</ul>

<p>В CE можно кодировать бинарные признаки, упорядоченные по алфавиту или численному возрастанию признаки, а также географические, геометрические данные, данные о времени и другие структурированные данные. Единственное ограничение — решение не предоставляет собственного способа для создания масок для выборочного кодирования.</p>

<h2 id="что-имеется-в-наборе-ce">Что имеется в наборе CE</h2>

<h3 id="contrast-coding">Contrast Coding</h3>

<p>Данный тип кодирование разбивает признак на уровни (в каждом только значения, относящиеся к одной категории). Затем для каждого уровня вычисляется некоторая статистика. Например, вот так это делается в <a href="http://www.statsmodels.org/dev/contrasts.html">statsmodels</a>. Метод подходит для кодирования номинальных и частично упорядоченных признаков.</p>

<p>В CE реализованы следующие кодеры:</p>

<ul>
  <li>
    <p>Backward Difference Coding — сравнивается среднее для уровня со средним предыдущего уровня</p>
  </li>
  <li>
    <p>Helmert Coding — сравнивается среднее для уровня со средним для всех последующих уровней. Больше подходит для номинальных переменных.</p>
  </li>
  <li>
    <p>Sum Coding — сравнивается среднее для уровня со средним для всех остальных уровней</p>
  </li>
  <li>
    <p>Polynomial Coding — используются линейные, квадратичные и кубические представления целевой категории. Подходит исключительно для упорядоченных признаков, интервалы между категориями которых одинаковы. Ну и довольно прожорлив по памяти.</p>
  </li>
</ul>

<p>Не реализованы:</p>

<ul>
  <li>
    <p>Deviation Coding — более общий случай суммирующего кодирования, когда сравнение идет со всеми уровнями</p>
  </li>
  <li>
    <p>Dummy Coding — сравнение со средним значением на уровне</p>
  </li>
  <li>
    <p>Simple Coding — то же самое, что и Dummy Coding, только в качестве среднего принимается среднее всех значений фиксированного уровня</p>
  </li>
  <li>
    <p>Reverse Helmet Coding</p>
  </li>
  <li>
    <p>Forward Difference Coding</p>
  </li>
</ul>

<p>Больше подробностей <a href="https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/">смотри тут</a></p>

<h3 id="target-based-coding">Target-based Coding</h3>

<p>Для кодирования переменных используются сведения о разметке (цели) дата-сета. Тут надо знать следующие понятия: <script type="math/tex">y</script> общее число примеров, <script type="math/tex">y^+</script> число примеров, отнесенных к «положительному» классу, <script type="math/tex">n</script> число примеров на уровне, <script type="math/tex">n^+</script> число примеров уровня, отнесенных к положительному классу, <script type="math/tex">\alpha</script> регуляризирующий параметр, <script type="math/tex">prior</script> среднее значение цели. В CE реализованы:</p>

<ul>
  <li>
    <p>Target Encoder. Переменная кодируется по формуле <script type="math/tex">x^k = prior*(1 - s)</script> <script type="math/tex">+ s*\frac{n^+}{n}</script>, где <script type="math/tex">s = \frac{1}{1 + \exp(\frac{-n - mdl}{\alpha})}</script>, а <script type="math/tex">\scriptsize mdl</script> — минимум среди всех примеров на уровне.</p>
  </li>
  <li>
    <p>James-Stein Encoder кодируется по формуле <script type="math/tex">x^k = (1 - B) * \frac{n^+ + prior*m}{u^+ + m}</script> <script type="math/tex">+ B*\frac{y^+}{y}</script>, где <script type="math/tex">B</script> дополнительный гиперпараметр, регулирующий переобучение</p>
  </li>
  <li>
    <p>M-estimate кодируется по формуле <script type="math/tex">x^k = \frac{n^+}{n} + B * \frac{y^+}{y}</script>, где <script type="math/tex">m = 1... 100</script> — дополнительный гиперпараметр, регулирующий переобучение. По сути — упрощенный вариант Target Encoder. (На момент написания статьи кодировщик работает некорректно)</p>
  </li>
  <li>
    <p>Weight of Evidence (WOE) считается по формуле <script type="math/tex">x^k = \ln(\frac{nominator}{denominator})</script>, где <script type="math/tex">nominator = \frac{n^+ + \alpha}{y^+ + 2\alpha}</script>, <script type="math/tex">denominator = \frac{n - n^+ + \alpha}{y - y^+ + 2\alpha}</script>. Кодировщик часто используется для подсчета рисков и других скорингов, т.к. по сути производит упорядочивание в логарифмическом масштабе. Хорошо решает проблему стандартизации и группировки разреженных данных. Проблема — теряются данные на биннинге, не учитывается корреляция между зависимыми данными и сам кодировщик легко может переобучиться.</p>
  </li>
</ul>

<p>Альтернативой WOE является PRE (Probability Ratio Encoding). В этом случае для каждой метки вычисляется <script type="math/tex">P(1)/P(0)</script>, т.е отношение вероятностей того, что объект размечен положительно и вероятность отрицательной разметки. Этим значением заменяется значение при кодировании. <script type="math/tex">P(0)</script> естественно ни при каких условиях не принимается равным 0. В CE метод не реализован.</p>

<ul>
  <li>
    <p>Leave One Out (LOO) считается среднее цели для примера выбранной категории, для случая, когда пример удален из дата-сета.</p>
  </li>
  <li>
    <p>Catboost Encoder улучшенный LOO (<a href="https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html">документация</a>)</p>
  </li>
</ul>

<p>У всех target-based кодировщиков имеет место проблема риска переобучения, так как используются данные о разметке дата-сета. Два варианта решения — дополнительная регуляризация и двойная кросс-валидация. Кроме того LOO и Catboost Encoder работают плохо, если реальные данные имеют другую размерность, что приводит к сдвигу по отноешнию к данным, на которых производилось обучение.</p>

<h3 id="остальные-кодировщики">Остальные кодировщики</h3>

<p>В CE реализовано несколько базовых кодировщиков:</p>

<ul>
  <li>
    <p>One Hot — аналог OnHotEncoder в scikit-learn или get_dummies в pandas</p>
  </li>
  <li>
    <p>Ordinal только для упорядоченных признаков (обратите внимание при импорте, что класс в CE называется также, как OrdinalEncoder в scikit-learn)</p>
  </li>
  <li>
    <p>Binary конвертит категории признака в бинарный код. Категории конвертятся в номера по порядку, затем номера кодируются на двоичной базе, а затем единицы и нули из полученых кодированных значений выносятся в новые признаки. По сути, <script type="math/tex">n</script> категорий переводятся в <script type="math/tex">log_{2}n</script> бинаризированных признаков. Это весьма значительно сокращает количество признаков на выходе по сравнению с One Hot и полезно, когда число кодируемых категорий значительно.</p>
  </li>
  <li>
    <p>Base N комбинирует One Hot и Binary</p>
  </li>
</ul>

<p>Кроме того, реализован Hashing, позволяющий хешировать категории. Это аналог FeatureHasher (последний больше подходит для работы с текстом). Также походит для кодирования большого числа категорий, так как сокращает размерность на выходе по сравнению с One Hot.</p>

<h3 id="чего-нет-в-ce">Чего нет в CE</h3>

<p>Не реализован Label Encoding. Можно воспользоваться factorize из pandas или LabelEncoder из sklearn или Ordinal, что то же самое. Не реализован Frequincy Encoding, когда категории кодируются в числовом виде в зависимости от частоты для признака в диапазоне [0, 1]. Кроме того, нет методов для кодирования признаков, которые явно упорядочены циклически, например, дат и времени. Ну и, естественно, нет методов для конструирования признаков, таких как разделение выражения на части и т.д. Все это придется написать самостоятельно или искать более специфическое решение.</p>

<h2 id="как-использовать-кодирование-категориальных-признаков">Как использовать кодирование категориальных признаков</h2>

<p>Есть множество разных рекомендаций. Все их можно свести к следующему:</p>

<ol>
  <li>
    <p>Определить, относится ли вообще признак к категориальному и посчитать количество категорий.</p>
  </li>
  <li>
    <p>Необходимо понять природу категориального признака, отнести его к номинальному или упорядоченному типу, установить циклические зависимости для категорий и другие особенности распределения категорий</p>
  </li>
  <li>
    <p>Необходимо знать, к какому распределению данных лучше приспособлена обучаемая модель. Это позволит сразу выбрать наиболее оптимальный метод кодирования</p>
  </li>
  <li>
    <p>Методы, использующие гиперпараметры, желательно сразу включить в цикл поиска оптимального решения.</p>
  </li>
  <li>
    <p>Для частично упорядоченных признаков понять, можно ли соотнести категории с численными значениями, расположенными на эквивалентных интервалах. Если да, то стоит подумать о применении Ordinal Encoding. если нет, то можно попробовать один из методов контрастного кодирования. Если же количество категорий велико и есть проблемы с вычислительной сложностью по памяти, можно попробовать один из методов кодирования, сокращающий выходную размерность, например, хеширование. При этом надо помнить, что это может привести к потере данных.</p>
  </li>
  <li>
    <p>Для неупорядоченных признаков можно использовать One Hot, если число категорий невелико. Большое количество категорий  можно также бинаризировать или хешировать, если потеря части данных приемлема. Если нет, придется использовать один из методов target encoding. Необходимо помнить о переобучении и построить, при необходимости, двойную кросс-валидацию.</p>
  </li>
  <li>
    <p>На практике, на мой взгляд, можно миксовать различные методы, попутно расширяя пространство признаков. Например, можно сконструировать новые признаки, применить относительно простые кодировщики к части исходных, а на выходе закодировать весь пул по цели. Пространство для экспериментов ограничено, как всегда, только по вычислительной сложности.</p>
  </li>
</ol>

<p>Дополнительные статьи по этой тематике: <a href="https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02">один</a>, <a href="https://towardsdatascience.com/benchmarking-categorical-encoders-9c322bd77ee8">два</a></p>

  </div>
    <script src="https://utteranc.es/client.js"
        repo="KonstantinKlepikov/KonstantinKlepikov.github.io"
        issue-term="url"
        label="blog-comments"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
    <div class="pay">
    <iframe src="https://yoomoney.ru/quickpay/shop-widget?writer=seller&targets=%D0%9F%D0%BE%D0%B4%D0%B4%D0%B5%D1%80%D0%B6%D0%B0%D1%82%D1%8C%20%D1%81%D0%B0%D0%B9%D1%82%20konstantinklepikov.github.io&targets-hint=%D0%9D%D0%B0%20%D0%BF%D0%BE%D0%B4%D0%B4%D0%B5%D1%80%D0%B6%D0%BA%D1%83%20%D1%81%D0%B0%D0%B9%D1%82%D0%B0&default-sum=100&button-text=12&payment-type-choice=on&mobile-payment-type-choice=on&hint=&successURL=https%3A%2F%2Fkonstantinklepikov.github.io%2F&quickpay=shop&account=410013688263668&" width="100%" height="250" frameborder="0" allowtransparency="true" scrolling="no"></iframe>
</div>
    <div id="share-bar">

    <h4>Поделиться статьей</h4>

    <div class="share-buttons">
        <a href="https://twitter.com/intent/tweet?text=Подготовка данных: кодирование категориальных признаков&url=https://konstantinklepikov.github.io/2019/10/28/data-preprocessing-category-encoders.html" onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Поделиться на Twitter" class="link-primary" target="_blank" rel="noopener">
            <i class="fa fa-twitter share-button"> twitter</i>
        </a>

        <a href="https://vk.com/share.php?url=https://konstantinklepikov.github.io/2019/10/28/data-preprocessing-category-encoders.html&title=Подготовка данных: кодирование категориальных признаков" title="Поделиться в vkontakte" class="link-primary" target="_blank" rel="noopener">
            <i class="fa fa-vk share-button"> vkontakte</i>
        </a>

        <a  href="mailto:?subject=Подготовка данных: кодирование категориальных признаков&body=Check out this site https://konstantinklepikov.github.io/2019/10/28/data-preprocessing-category-encoders.html"
        title="Отправить по почте" >
        <i class="fa fa-envelope share-button"> email</i>
    </a>
    </div>

</div>
  

  <p class="h4 mt-2">Все статьи с тегом <a href="/tag/category-encoders" class="link-tags">category-encoders</a></p>
  <div class="prose mb-2">
    <ul>
        
        <li><a href="/2019/10/28/data-preprocessing-category-encoders.html" title="Подготовка данных: кодирование категориальных признаков">Подготовка данных: кодирование категориальных признаков</a> (28 Oct 2019)<br>
            
        </li>
        
    </ul>
  </div>

</article>

<div class="container mx-auto px-2 py-2 clearfix">
  <!-- Use if you want to show previous and next for all posts. -->



  <div class="col-4 sm-width-full left mr-lg-4 mt-3">
    <a class="no-underline border-top-thin py-1 block" href="https://konstantinklepikov.github.io/2019/10/19/complexity-basics-terms.html" title="Вычислительная сложность машинного обучения. Базовые принципы">
      <span class="h5 link-secondary text-accent">Предыдущая запись</span>
      <p class="bold h3 link-primary mb-1">Вычислительная сложность машинного обучения. Базовые принципы</p>
      <p>Чуть ранее, в статье временная сложность алгоритмов машинного обучения, я разбирал временную сложность некоторых алгоритмов из библиотеки scykit-learn. Настало время...</p>
    </a>
  </div>
  
  
  <div class="col-4 sm-width-full left mt-3">
    <a class="no-underline border-top-thin py-1 block" href="https://konstantinklepikov.github.io/2019/12/15/statistics-terms-for-data-science.html" title="Краткий справочник по терминам статистики, которые пригодятся для data science. Часть 1">
      <span class="h5 link-secondary text-accent">Следующая запись</span>
      <p class="bold h3 link-primary mb-1">Краткий справочник по терминам статистики, которые пригодятся для data science. Часть 1</p>
      <p>В данной статье кратко пройду по терминологии из практической статистики и ее применеии в data science. Термины приводятся в упрощенном...</p>
    </a>
  </div>


</div>

    </div>

    <div class="border-top-thin clearfix mt-2 mt-lg-4">
  <div class="container mx-auto px-2">
    <p class="col-8 sm-width-full left py-2 mb-0">Этот проект поддерживается <a class="text-accent" href="https://github.com/KonstantinKlepikov">KonstantinKlepikov</a></p>
    <ul class="list-reset right clearfix sm-width-full py-2 mb-2 mb-lg-0">
      <li class="inline-block mr-1">
        <a href="https://twitter.com/share" class="twitter-share-button" data-hashtags="My deep learning">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
      </li>
      <li class="inline-block">
        <a class="github-button" href="https://github.com/KonstantinKlepikov/" data-icon="octicon-star" data-count-href="KonstantinKlepikov//stargazers" data-count-api="/repos/KonstantinKlepikov/#stargazers_count" data-count-aria-label="# stargazers on GitHub" aria-label="Star KonstantinKlepikov/ on GitHub">Star</a>
      </li>
    </ul>
  </div>
</div>


  </body>

</html>
