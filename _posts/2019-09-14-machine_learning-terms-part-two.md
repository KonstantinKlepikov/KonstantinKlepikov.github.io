---
layout: post
title: "Основные термины машинного обучения. Часть №2"
date: 2019-09-14
tags: machine-learning
tag-for-sollecting: machine-learning
keywords: машинное обучение machine learning data science классификация регрессия Гудфеллоу
---

В [первой части]({{site.baseurl}}{% link _posts/2019-08-31-machine_learning-terms.md %}) статьи я разобрал базовую терминологию ML: постановку задачи, емкость, переобучение и недообучение, регуляризацию и гиперпараметры, точечную оценку, смещение оценки, дисперсию, стандартную ошибку и состоятельность, а так-же важные термины, определяемые в рамках этих терминов. Продолжим.

## Оценка максимального правдоподобия

$$\theta{\tiny ML} = \underset{\theta}{\arg\max}\ p{\tiny model}(\mathbb{X};\theta) =$$ $$\underset{\theta}{\arg\max}\ \underset{i=1}{\overset{m}{\prod}}\ p{\tiny model}(\mathbf{x}^{(i)};\theta)$$, где:

$$\mathbb{X} = \{ x^{(1)}, ... x^{(m)} \}$$ — множество, состоящее из $$m$$ примеров, независимо выбираемых из неизвестного порождающего распределения $$p{\tiny data}(\mathbf{x})$$. В выражении максимального правдоподобия $$p{\tiny model}(\mathbf{x};\theta)$$ — параметрическое семейство распределений вероятности над  одним и тем же пространством, индексированное параметром $$\theta$$

Произведение неудобно по причине, т.к. подвержено потере значимости. Взятие логарифма не изменяет $$\arg\max$$, но позволяет преобразовать произведение в сумму: $$\theta{\tiny ML} = \underset{\theta}{\arg\max}\ \underset{i=1}{\overset{m}{\sum}}\ \log\ p{\tiny model}(\mathbf{x}^{(i)};\theta)$$

Если разделить правую часть на $$m$$ (умножение функции стоимости на константу не изменяет $$\arg\max$$), мы получаем математическое ожидание относительного эмпирического распределения $$\hat{p}{\tiny data}$$ определяемого обучающими данными: $$\theta{\tiny ML} = \underset{\theta}{\arg\max}\ \mathbb{E}{\scriptsize x-\hat{p}{\tiny data}}\ \log\ p{\tiny model}(\mathbf{x};\theta)$$

Максимальное правдоподобие — это попытка совместить модельное распределение с эмпирическим $$\hat{p}{\tiny data}$$, в идеале мы хотим получить совпадение истинного и порождающего распределения $$p{\tiny data}$$. Это интерпретируется с помощью минимизации расхождения Кульбака-Лейблера.

### Условное логарифмическое правдоподобие

Если $$\mathbf{X}$$ представляет все входы, $$\mathbf{Y}$$ все наблюдаемые выходы, а все примеры независимы и одинаково распределены, то условное логарифмическое правдоподобие: $$\theta{\tiny ML} = \underset{\theta}{\arg\max}\ \underset{i=1}{\overset{m}{\sum}}\ \log\ P(\mathbf{y}^{(i)}\mid\mathbf{x}^{(i)};\theta)$$

## Байесовская статистика

В отличие от частотного метода, в котором предполагается, что истинное значение $$\theta$$ фиксировано хотя и неизвестно, а точечная оценка $$\hat{\theta}$$ — случайная величина, в байесовском подходе к статистике истинный параметр $$\theta$$ неизвестен или недостоверен и представляется случайной величиной, а набор данных случайной величиной не является, т.к. доступен прямому наблюдению. До наблюдения данных  мы представляем свое знание о $$\theta$$ в качестве априорного распределения вероятности $$p(\theta)$$. Тогда можно реконструировать влияние данных на наши гипотезы о $$\theta$$, объединив правдоподобие данных с априорным посредством теоремы Байеса:

$$p(\theta\mid x^{(1)}, ... x^{(m)}) =$$ $$\frac{p(x^{(1)}, ... x^{(m)}\mid\theta)p(\theta)}{p(x^{(1)}, ... x^{(m)})}$$, где $$x^{(1)}, ... x^{(m)}$$ — набор наблюдаемых примеров.

В отличие от оценки максимального правдоподобия, где предсказания делаются с использованием точечной оценки $$\theta$$, в байесовской оценке  предсказания делаются с помощью полного распределения $$\theta$$. к примеру, после наблюдения $$m$$ примеров предсказанное распределение следующего $$x^{m+1}$$ примера описывается формулой: $$p(x^{m+1}\mid x^{(1)}, ... x^{(m)}) =$$ $$\int p(x^{m+1}\mid\theta)p(\theta\mid x^{(1)}, ... x^{(m)})d\theta$$. Если после наблюдения $$x^{(1)}, ... x^{(m)}$$ примеров мы все еще не знаем $$\theta$$, то эта неопределенность включается непосредственно в предсказания.

Кроме того, при байесовской оценке происходит сдвиг плотности вероятности в сторону тех областей пространства параметров, которые априори предпочтительны, что обусловлено значительным влиянием байесовского априорного распределения. Зачастую это приводит к предпочтению более простых и гладких моделей.

Байесовские модели обобщаются лучше при ограниченном числе обучающих данных, но с ростом данных обучение становится вычислительно более накладным.

### Оценка априорного максимума

В большинстве случаев операции, включающие апостериорное байесовское распределение, недопустимы с точки зрения временной сложности алгоритмов. В этом случае точечная оценка $$\theta$$ дает разрешимую апроксимацию. Чтобы использовать преимущества байесовской оценки, разрешив априорному распределению влиять на выбор точечной оценки, применяют оценку апостериорного максимум (MAP):

$$\theta{\tiny MAP} = \underset{\theta}{\arg\max}\ p(\theta\mid\mathbf{x})\ =$$ $$\underset{\theta}{\arg\max}\ \log\ p(\theta\mid\mathbf{x})$$ $$+ \log\ p(\theta)$$, где $$\log\ p(\theta\mid\mathbf{x})$$ — стандартное логарифмическое правдоподобие, а $$\log\ p(\theta)$$ соответствует априорному распределению.

## Проблемы, требующие глубокого изучения

### Проклятие размерности

С увеличением размерности данных количество представляющих интерес конфигураций растет экспоненциально. Если имеется $$d$$ измерений и нужно различать $$v$$ значений вдоль каждой оси, то потребуется $$O(v^{d})$$ областей и примеров.

### Регуляризация для достижения локального постоянства и гладкости

Чтобы алгоритм хорошо обобщался, необходимо иметь априорное представление о том, какого рода функцию он должен обучить. Самое распространенные априорные предположения — **априорное предположение о гладкости** или **априорное предположение о локальном постоянстве**. Это означает, что обучаемая функция не должна сильно изменяться в небольшой области.

Обобщаемость большинства алгоритмов опирается на этот принцип, поэтому они плохо масштабируются на многие статистические задачи.

### Обучение многообразий

В основе ML лежит концепция **многообразия** — множества точек, ассоциированных с окрестностью каждой точки. Из этой концепции вытекает существование преобразований для перемещения из одного места многообразия в другое.

В ML многообразие — это связное множество точек в пространстве высокой размерности, которое можно хорошо аппроксимировать, вводя в рассмотрение лишь небольшое число степеней свободы, или измерений. В машинном обучении допускаются многообразия, размерность которых различна в разных точках.

Многие алгоритмы ML безнадежны, если ожидается, что в результате обучения алгоритм должен найти функции с нетривиальными изменениями во всем пространстве $$\mathbb{R}^{n}$$. Алгоритмы обучения многообразий преодолевают это препятствие, предполагая, что большая часть $$\mathbb{R}^{n}$$ — недопустимые входные данные, а интересующие нас входы сосредоточены только в наборе многообразий, содержащем небольшое подмножество точек, причем интересные изменения результирующей функции будут происходить только вдоль направлений, принадлежащих какому-то одному многообразию, или при переходе с одного многообразия на другое.

**Данное краткое описание составлено на основе книги «Глубокое обучение» за авторством Я.Гудфеллоу, И.Бенджио, А.Курвилль**
