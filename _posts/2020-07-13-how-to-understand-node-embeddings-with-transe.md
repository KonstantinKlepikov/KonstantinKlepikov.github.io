---
layout: post
title: "Как понять translating алгоритмы для графов?"
date: 2020-07-13
tags: graphs sc224w TransE translating algorithms
tag-for-sollecting: TransE
keywords: теория графов графы translating TransE sc224w эмбеддинг embedding
---

Алгоритм TransE (Translating Embeddings for Modeling Multi-relational Data) задает представление точек и связей графа в некоем пространстве векторов и сводит к минимуму критерий ранжирования.

Translating алгоритмы (а точнее TransE), рассматриваются в курсе cs224w, про них есть домашка и они фигурируют в нескольких последних лекциях, есть смысл разобраться в том, как именно они устроены. Также как и в курсе, будем разбираться на примере TransE.

В начале сам алгоритм:

![TransE](../../../assets/img/130720-01.png)

Мы имеем некий граф знаний $$G = (E, S, L)$$, в котором $$E$$ - это множество нод (entities), $$S$$ - множество ребер, а $$L$$ - множество возможных связей.

$$S$$ содержит триплеты $$(h, l, t)$$, определяемые следующим образом:

$$h \in E$$ - исходящая нода (head)

$$l \in L$$ - связь (relation)

$$t \in E$$ - нода, завершающая связь (tail)

Можно представить себе граф, в котором существуют точки, для которых сложно определить близость основываясь на классических методах. Например город Москва (head) является столицей России (tail). Между данными нодами графа есть некая связь (relation), определяющая отношение вершин графа. Задача алгоритма TransE обучиться такому векторному представлению для $$(h, l, t)$$, что-бы оно отображало имеющиеся в графе подобия. Итак, необходимо представить head, tail и relation в пространстве $$\in \mathbb{R}^k$$ (где $$k$$ - это кол-во измерений), после чего обучить алгоритм таким образом, чтобы сумма head и relation была как можно ближе к tail.

Если мы исходим из того, что $$(h, l, t) \in S$$ и предполагаем что $$\mathbf{h} + \mathbf{l} \approx \mathbf{t}$$. Такие триплеты мы можем считать "правильными". Тогда можно предположить существование и "неправильных" (corrupted) триплетов $$(h', l, t') \in S'$$, выбранных из некого $$S'_{(h, l, t)}$$в котором $$h$$ или $$t$$ (но не оба одновременно) заменены на случайные, входящие в $$S$$.

К примеру Берлин в нашем графе мог бы оказаться столицей России, но к счастью, такой связи мы не наблюдаем.

Итак, функция потерь, которую будет минимизирвоать TransE, выглядит так:

$$\mathcal{L} = \underset{(h,l,t) \in S}\sum (\underset{(h',l,t') \in S'_{(h,l,t)}}\sum [\gamma + d(\mathbf{h} + \mathbf{l}, \mathbf{t}) - d(\mathbf{h}' + \mathbf{l}, \mathbf{t}')]_{+} )$$

Нам необходимо сделать так, чтобы разница правильных и неправильных эмбеддингов (с учетом зазора $$\gamma$$) $$d_{+}$$ и $$d_{-}$$ (с регуляризацией по норме $$L_{1}$$ или $$L_{2}$$) стремилась к нулю сверху. Для этого мы будем использовать стохастический градиентный спуск с минибатчами через все $$\mathbf{h}$$, $$\mathbf{l}$$ и $$\mathbf{t}$$. Триплеты будем выбирать семплированием, а инициализируем всю конструкцию случайными значениями.

Что будет делать алгоритм?

- вначале мы случайным образом инициализируем все вектора $$\mathbf{l}$$ для каждого $$l \in L$$ и все вектора $$\mathbf{e}$$ для всех entities в графе

- далее, нормализуем эмбеддинги, что-бы исключить тривиальную оптимизацию по кратчайшим расастояниям

- затем, уже в цикле, будем определять размер минибатчей и иницилизировать сеттриплетов - для каждого правильного в минибатче будем получать неправильный

- наконец будем считать лосс и обновлять эмбеддинги в направлении градиента

Еще раз на примере векторов:

![TransE vectorised](../../../assets/img/130720-02.png)

Мы получаем сумму разниц правильных и неправильных эмбедингов следуя через все пространство вещественных значений $$h,l,t$$ и $$h',l,t'$$ до тех пор пока не выкинем все несвязанные пары нод. Все что осталось, очевидно имеет искомый relation.

Возникает ряд вопросов. Во-первых, почему-бы не использовать лос попроще? Например, можно не усложнять и сводить в ноль сумму эмбеддингов всех правильных триплетов.

$$\mathcal{L}_{simple} = \underset{(h,l,t) \in S}\sum d(\mathbf{h} + \mathbf{l}, \mathbf{t})$$

Проблемы начинаются с того, что такая метрика способна найти связи, которых на самом деле в графе нет. Посмотрим на такой граф:

![TransE vectorised](../../../assets/img/130720-03.png)

Вася купил стиральную машину и Петя купил стиральную машину. Стиральная машина постирала рубашки. Но стоп... Вася постирал Петю?

![TransE vectorised](../../../assets/img/130720-04.png)

Такого бы не случилось, если бы мы оптимизировали метрику, с $$(h', l, t') \in S'$$ - перебирая $$h'$$ или $$t'$$ мы очень быстро сводим в ноль потери для данного графа, не создавая несуществующих связей.

Для чего нужен параметр $$\gamma$$?

Подробнее про TransE можно прочитать в статье [Translating Embeddings for Modeling Multi-relational Data](https://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf). Этот и другие методы для эмбеддингов на графах можно посмотреть [тут](https://arxiv.org/pdf/1705.02801.pdf), [тут](https://arxiv.org/pdf/1709.07604.pdf) и [тут](https://arxiv.org/pdf/1703.08098.pdf). О том, как translating-модели применяются в совместной фильтрации в рекомендательных системах, можно посмотреть [здесь](https://arxiv.org/pdf/1909.03193.pdf).
