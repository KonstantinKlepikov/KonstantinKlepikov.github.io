---
layout: post
title: "Основные термины машинного обучения. Часть №1"
date: 2019-08-31
tags: machine-learning
tag-for-collecting: machine-learning
keywords: машинное обучение machine learning data science классификация регрессия Гудфеллоу
---

Практически все алгоритмы машинного обучения можно описать как комбинацию набора данных, функции стоимости, процедуры оптимизации и модели. Любой из этих компонентов можно заменить, как правило, независмо от других. Такая формула построения алгоритма обучения подходит для обучения как с учителем, так и без. Пройдем по терминам, которые позволяют определить machine learning.

Алгоритм обучается на опыте $$E$$ относительно некоего класса задач $$T$$ и меры качества $$P$$, если качество на задачах из $$T$$, измеряемое с помощью $$P$$, возрастает с ростом опыта $$E$$.

### Задача $$T$$

Есть несколько типов задач, которые можно решить с помощью машинного обучения.

- **Классификация**. В задачах этого типа алгоритм должен ответить, какой из $$k$$ категорий принадлежит некоторый пример. Для решения этой задачи алгоритм обучения обычно просят породить функцию $$f : \mathbb{R}^{n} \rightarrow \{1, ..., l\}$$. Если $$y = f(\mathbf{x})$$, то модель относит входной пример, описываемый вектором $$\mathbf{x}$$, к категории с числовым кодом $$y$$. Есть и другие варианты классификации, например, когда $$f$$ — распределение вероятности принадлежности к классам.

- **Классификация при отсутствии части данных**. Если часть входных данных отсутствует, алгоритм должен обучить набор функций, вместо единственной, отображающей входной вектор на код категории. Один из способов обучить такое подмножество функций — обучить распределение вероятности всех релевантных величин, а затем решить задачу классификации, вычислив маргинальное распределение отсутствующих значений.

- **Регрессия**. Алгоритм должен предсказать числовое значение по входным данным. Для решения этой задачи необходимо породить функцию $$f : \mathbb{R}^{n} \rightarrow \mathbb{R}$$. Результатом регрессии является прогноз некоего значения.

- **Транскрипция**. В задаче этого типа предлагается проанализировать неструктурированное представление данных и преобразовать его в текст.

- **Машинный перевод**. Входные данные — это последовательность данных на одном языке, а алгоритм должен преобразовать ее в последовательность символов на другом языке.

- **Структурный вывод**.  В этой задаче на выходе порождается вектор (или иная структура, содержащая несколько значений), между элеменатами которого существуют некие, имеющие значение, связи. В сущности, в эту задачу входят и транскрипция с машинным переводом, а также грамматический разбор.

- **Обнаружение аномалий**. В данной задаче алгоритм анализирует входные данные и размечает часть из них, как аномальные.

- **Синтез и выборка**. В данной задаче алгоритм генерирует новые данные, сходные с обучающими данными. Примером может служить создание текстур или образов для компьютерных игр.

- **Подстановка отсутствующих значений**. Алгоритму предъявляется новый пример $$\mathbf{x} \in \mathbb{R}^{n}$$, в котором некоторые элементы $$x$$ отсутствуют. Алгоритм должен спрогнозировать значение отсутствующих элементов.

- **Шумоподавление**. В этой задаче алгоритму предъявляется не искаженный помехами пример $$\mathbf{\tilde{x}} \in \mathbb{R}^{n}$$, полученный из чистого примера $$\mathbf{x} \in \mathbb{R}^{n}$$, в результате неизвестного процесса искажения. Алгоритм должен восстановить чистый пример $$\mathbf{x}$$ по искаженному $$\mathbf{\tilde{x}}$$ либо вернуть $$P(\mathbf{x}\vert\mathbf{\tilde{x}})$$ условное распределение вероятности.

- **Оценка функции вероятности или плотности функции вероятности**. В данной задаче алгоритм должен обучить функцию $$P{\tiny model} : \mathbb{R}^{n} \rightarrow \mathbb{R}$$, где $$P{\tiny model}(\mathbf{x})$$ интерпретируется как функция плотности вероятности (если $$\mathbf{x}$$ непрерывная случайная величина) или как функция вероятности (дискретная величина), в пространстве, из которого были взяты примеры. Для решения этой задачи алгоритм должен уметь оценивать структуру данных, хотя бы неявно улавливать структуру распределения вероятности, а в задаче оценки плотности — явно.

### Мера качества $$P$$

Мера качества специфична для каждого алгоритма. Для задач классификации в основном измеряется accuracy (точность) модели — доля примеров, для которых модель выдала верное предсказание. Частота ошибок — противоположный вариант меры качества, показывающая долю примеров, для которых модель выдала неверное предсказание.

### Опыт $$E$$

Алгоритмы ML делятся на два больших класса:

- **Алгоритму обучения без учителя** предоставляются наборы данных, содержащих множество признаков, алгоритм должен выявить полезные структурные признаки набора.

- **Алгоритму обучения с учителем** предъявляются наборы данных, примеры в которых снабжены меткой (целевым классом)

Обучение без учителя означает наблюдение нескольких примеров случайного вектора $$\mathbf{x}$$ с последующей попыткой вывести, явно или неявно, распределение вероятности $$P(\mathbf{x})$$ или некие свойства этого распределения. Обучение с учителем сводится к наблюдению нескольких примеров случайного вектора $$\mathbf{x}$$ и ассоциированию с ним значения или вектора $$\mathbf{y}$$ с последующей попыткой вывести оценку $$P(\mathbf{x}\vert\mathbf{y})$$.

Обучение с учителем и без — понятия довольно размытые, многие алгоритмы подходят для решения и той и другой задачи. Принято считать, что задачи классификации, регрессии и структурного вывода относятся к обучению с учителем, а задача оценки плотности — к обучению без учителя.

Возможны и другие парадигмы обучения: обучение с частичным привлечением учителя, обучение с подкреплением и т.д.

### Ёмкость, переобучение и недообучение

Способность алгоритма ML хорошо работать на новых данных, которые он ранее не видел, называется **обобщением**. Мера ошибки алгоритма на обучающем наборе данных называется **ошибкой обучения** — ее необходимо минимизировать (задача оптимизации). **Ошибкой обобщения** называют математическое ожидание ошибки алгоритма на новых входных данных. Считается справедливым предположение, что данные из обучающего и тестового набора одинаково распределены, т.е. выбраны из одного и того же распределения вероятности, которое называется **порождающим распределением**. В этом контексте **недообучение** имеет место, когда модель не позволяет получить достаточно малую ошибку на обучающем наборе, а **переобучение** — когда разрыв между ошибками обучения и тестирования слишком велик. **Емкость (capacity)** позволяет управлять склонностью модели к переобучению или недообучению. Емкость описывает способность модели к аппроксимации широкого спектра функций. При маленькой емкости модель слишком простая и недообучается, при высокой — слишком сложная и переобучается.

Один из способов контроля за емкостью — выбор **пространства гипотез**, множества функций, которые алгоритм может рассматривать в качестве потенциального решения. **Репрезентативная емкость** определяет семейство функций, из которой модель может выбрать алгоритм обучения в процессе варьирования параметров. Как правило, по причине дополнительных ограничений, например, из-за несовершенства оптимизации, эффективная емкость алгоритма оказывается меньше репрезентативной.

### Теорема об отсутствии бесплатных завтраков

В среднем, по всем возможным порождающим определениям у любого алгоритма классификации частота ошибок классификации ранее не наблюдавшихся примеров одинакова. Это означает, что самый сложный алгоритм, в среднем (по всем возможным задачам) дает такое же качество, как и простейший. Цель ML заключается не в том, чтобы построить самый сложный или самый эффективный алгоритм, а в том, чтобы понять, какие виды распределений характерны реальным данным.

### Регуляризация

Регуляризация — это любая модификация алгоритма обучения, предпринятая с целью уменьшить его ошибку обобщения, не уменьшив при этом ошибку обучения. Из теоремы «об отсутствии бесплатных завтраках», в том числе вытекает то, что не существует наилучшего способа регуляризации.

### Гиперпараметры

Гиперпараметры управляют поведением алгоритма ML, при этом сам алгоритм не ищет значений гиперпараметров.

Попытка обучить гиперпараметр на обучающем наборе приводит к максимизации емкости модели и переобучению. Чтобы решить эту проблему, используется **контрольный набор**, который формируется из обучающего и никогда не используется в обучении. Если данных слишком мало, разделение на обучающий и тестовый наборы становится проблематичным, так как приводит к статистической недостоверности в оценке средней ошибки. Эту проблему решает **перекрестная проверка** — разделение исходного набора данных на подмножества и случайный выбор обучающего и контрольного набора в процессе обучения.

### Точечная оценка

Точечная оценка — это попытка найти единственное «наилучшее» представление интересующей величины. Это может быть один или несколько параметров либо некая функция.

Если $$\tilde{\theta}$$ — оценка параметра, а $$\{\mathbf{x}^{(1)}, ..., \mathbf{x}^{(m)}\}$$ — множество $$m$$ независимых т одинаково распределенных точек, то **точечной оценкой** или **статистикой** называется любая оценка этих данных: $$\tilde{\theta} = g(\mathbf{x}^{(1)}, ..., \mathbf{x}^{(m)})$$. В этом определении не требуется, чтобы $$g$$ возвращала значение, близкое к истинному значению $$\theta$$ или даже чтобы область значений $$g$$ совпадала со множеством допустимых значений $$\theta$$. При этом хорошей оценкой будет та, которая близка к истинному распределению $$\theta$$, из которого выбирались обучающие данные.

Точечную оценку также можно рассматривать как оценку связи между входной или выходной величинами. такой тип точечных оценок называется **оценкой функций**

### Смещение оценки

$$bias(\tilde{\theta}{\tiny m}) = \mathbb{E}(\tilde{\theta}{\tiny m}) - \theta$$, где:

математическое ожидание вычисляется по данным (рассматриваемым как выборка из случайной величины), $$\theta$$ — истинное значение параметра, которое определяет порождающее определение. $$\tilde{\theta}$$ является **несмещаной**, если $$bias(\tilde{\theta}{\tiny m}) = 0$$. Напротив, $$\tilde{\theta}$$ **асимптотически смещена**, если $$\lim{\scriptscriptstyle m\rightarrow\infty}\mathbb{E}(\tilde{\theta}{\tiny m}) = 0$$.

### Дисперсия и стандартная ошибка

Дисперсия оценки измеряет, как будет изменяться оценка, вычисленная по данным, при независимой повторной выборке из набора данных, генерируемого порождающим процессом. Желательны оценки, обладающие не только маленьким смещением, но и маленькой дисперсией.

$$Var(\tilde{\theta})$$, где случайной величиной является обучающий набор.

Стандартная ошибка — это квадратный корень из дисперсии. $$SE(\tilde{\theta})$$. На практике часто используется **стандартная ошибка среднего** $$SE(\tilde{\mu}{\scriptscriptstyle m})$$.

### Состоятельность

Схождение точечной оценки к истинным значениям при увеличении числа примеров называется состоятельностью: $$\lim{\scriptscriptstyle m\rightarrow\infty}\tilde{\theta}{\scriptscriptstyle m} = 0$$. Состоятельность гарантирует, что смещение оценки уменьшается с ростом числа примеров. При этом обратное неверно.

**Данное краткое описание составлено на основе книги «Глубокое обучение» за авторством Я.Гудфеллоу, И.Бенджио, А.Курвилль**
