---
layout: post
title: "Подготовка данных: кодирование категориальных признаков"
date: 2019-10-28
tags: preprocessing category-encoders sklearn scikit-learn ml-data
tag-for-sollecting: category-encoders
keywords: подготовка данных машинное обучение препроцессинг катигориальные признаки machine learning category encoders
---

В статье «[особенности препроцессинга данных в scikit-learn]({{site.baseurl}}{% link _posts/2019-10-08-scikit-learn-preprocessing.md %})» разбирались особенности кодирования признаков с помощью библиотеки scikit-learn. К сожалению, набор инструментов scikit-learn довольно скромный.

Часто данные содержат множественные категориальные признаки, часть из которых представлена несколькими категориями. В некоторых случаях категорий оказывается сравнительно много, по отношению к общему объему данных. Иногда значения в категориальных признаках распределены по-разному, в частности, могут быть определены какие-то серии, разбитые по времени. Все это не добавляет энтузиазма во время предварительной обработки данных.

К счастью, есть другие готовые решения, в т.ч. библиотека **[Category Encoders](https://contrib.scikit-learn.org/categorical-encoding/) (CE)**, предоставляющая широкий набор кодировщиков категориальных признаков.

## Какие преимущества у CE

1. Наверное, самое основное — это полная совместимость с scikit-learn. Доступны методы fit, fit_transform, get_params, set_params и transform. На основе CE можно строить пайплайны в scikit-learn.

2. Поддержка numpy и pandas. Что важно — pandas dataframe можно получить и на выходе кодировщика. Иногда это весьма полезно, особенно когда нужно выполнить выборочное кодирование. Это позволяет не городить самодельный забор из кодировщиков, а использовать CE непосредственно в пайплайне scikit-learn.

3. Есть возможность выбрать и явно указать кодируемые столбцы

4. Можно отбрасывать часть данных

5. Спроектированный кодировщик отлично портируется на рабочие данные.

## Какие задачи можно решать с помощью CE?

- кодирование номинальных признаков (nominal) — признаки, порядок которых не определен

- кодирование упорядоченных признаков (ordinal) признаки, порядок которых не частично определен

Можно кодировать бинарные признаки, упорядоченные по алфавиту или численному возрастанию признаки, а так же географические, геометрические данные, данные о времени и другие структурированные данные.

## Что имеется в наборе CE

### Contrast Coding

Данный тип кодирование разбивает столбец на уровни (в каждом только значения, относящиеся к одной категории). Затем для каждого уровня вычисляется некоторая статистика. Например, вот так это делается в [statsmodels](http://www.statsmodels.org/dev/contrasts.html). Метод подходит для кодирования номинальных и частично упорядоченных признаков.

В CE реализованы следующие кодеры:

- Backward Difference Coding — сравнивается среднее для уровня со средним предыдущего уровня

- Helmert Coding — сравнивается среднее для уровня со средним для всех последующих уровней. Больше подходит для номинальных переменных.

- Sum Coding — сравнивается среднее для уровня со средним для всех остальных уровней

- Polynomial Coding — используются линейные, квадратичные и кубические представления целевого признака. Подходит исключительно для упорядоченных признаков, интервалы между которыми одинаковы.

В CE не реализованы:

- Deviation Coding — более общий случай суммирующего кодирования, когда сравнение идет со всеми уровнями

- Dummy Coding — сравнение со средним значением на уровне уровнем

- Simple Coding — то же самое, что и Dummy Coding, только в качестве среднего принимается среднее всех значений фиксированного уровня

- Reverse Helmet Coding

- Forward Difference Coding

Больше подробностей [смотри тут](https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/)

### Target-based Coding

Для кодирования переменных используются сведения о разметке (цели) дата-сета. Для кодирования обычно используются следующие понятия: $$y$$ общее число примеров, $$y^+$$ число примеров, размеченных «положительной» целью, $$n$$ число примеров в уровне, $$n^+$$ число примеров уровня, отнесенных к положительному классу, $$\alpha$$ регуляризирующий параметр, $$prior$$ среднее значение цели. В CE реализованы:

- Target Encoder. Переменная кодируется по формуле $$x^k = prior*(1 - s)$$ $$+ s*\frac{n^+}{n}$$, где $$s = \frac{1}{1 + \exp(\frac{-n - mdl}{\alpha})}$$, а $$\scriptsize mdl$$ — минимум среди всех примеров на уровне.

- James-Stein Encoder кодируется по формуле $$x^k = (1 - B) * \frac{n^+ + prior*m}{u^+ + m}$$ $$+ B*\frac{y^+}{y}$$, где $$B$$ дополнительный гиперпараметр, регулирующий переобучение

- M-estimate кодируется по формуле $$x^k = \frac{n^+}{n} + B * \frac{y^+}{y}$$, где $$m = 1... 100$$ — дополнительный гиперпараметр, регулирующий переобучение. (На момент написания статьи кодировщик работает некорректно)

- Weight of Evidence (WOE) считается по формуле $$x^k = \ln(\frac{nominator}{denominator})$$, где $$nominator = \frac{n^+ + \alpha}{y^+ + 2\alpha}$$, $$denominator = \frac{n - n^+ + \alpha}{y - y^+ + 2\alpha}$$

- Leave One Out (LOO) считается среднее цели для примера выбранной категории, для случая, когда пример удален из дата-сета.

- Catboost Encoder улучшенный LOO ([документация](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html))

У всех target-based кодировщиков имеет место проблема риска переобучения, так как используются данные о разметке дата-сета. Два варианта решения — дополнительная регуляризация и двойная кросс-валидация. Кроме того, последние два плохо работают, если реальные данные имеют другую размерность, нежели те, на которых обучалась модель.

### Остальные кодировщики

В CE реализовано несколько базовых кодировщиков:

- Binary и One Hot — аналоги OnHotEncoder в scikit-learn

- Base N комбинация One Hot и Binary

- Ordinal аналог LabelEncoder или OrdinalEncoder в scikit-learn (обратите внимание при импорте, что класс в CE называется также, как OrdinalEncoder в scikit-learn)

Кроме того, реализован Hashing, позволяющий хешировать переменную. Это аналог FeatureHasher (последний больше подходит для работы с текстом).

К сожалению, в библиотеке в принципе не реализованы методы работы с категориальными признаками, распределенными по времени.

Дополнительные статьи по этой тематике: [один](https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02), [два](https://towardsdatascience.com/benchmarking-categorical-encoders-9c322bd77ee8)
